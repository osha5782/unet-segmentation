{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasohasakii/unet-segmentation/blob/master/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXF0mNZVGrRc",
        "colab_type": "code",
        "outputId": "ce3ab9a1-6d0c-453d-896d-147c0d656d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!rm -rf *\n",
        "!git clone https://github.com/yasohasakii/unet-segmentation.git\n",
        "!cp -r unet-segmentation/* ./\n",
        "!rm -rf unet-segmentation/"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unet-segmentation'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 233 (delta 8), reused 0 (delta 0), pack-reused 200\n",
            "Receiving objects: 100% (233/233), 513.91 MiB | 32.54 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Checking out files: 100% (220/220), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns9YXewiU0H8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcav7XpTWFKJ",
        "colab_type": "code",
        "outputId": "e570901d-32e3-4d00-8298-c38af0c700ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
        "    return c, p\n",
        "\n",
        "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
        "    concat = keras.layers.Concatenate()([us, skip])\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c\n",
        "\n",
        "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c\n",
        "def UNet():\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = keras.layers.Input((512, 512, 3))\n",
        "    \n",
        "    p0 = inputs\n",
        "    c1, p1 = down_block(p0, f[0]) #128 -> 64\n",
        "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
        "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
        "    c4, p4 = down_block(p3, f[3]) #16->8\n",
        "    \n",
        "    bn = bottleneck(p4, f[4])\n",
        "    \n",
        "    u1 = up_block(bn, c4, f[3]) #8 -> 16\n",
        "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
        "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
        "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
        "    \n",
        "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    return model\n",
        "model = UNet()\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 512, 512, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 512, 512, 16) 2320        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 256, 256, 16) 0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 256, 256, 32) 4640        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 32) 0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 128, 128, 64) 18496       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 128 0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_5[0][0]            \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 512, 512, 32) 0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 512, 512, 48) 0           up_sampling2d_7[0][0]            \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 512, 512, 16) 6928        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 512, 512, 16) 2320        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 512, 512, 1)  17          conv2d_36[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,962,625\n",
            "Trainable params: 1,962,625\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N74gPOQWabV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGen(keras.utils.Sequence):\n",
        "    def __init__(self, path, batch_size=1, image_size=512):\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        files = os.listdir(self.path)\n",
        "        files = [os.path.join(self.path,x) for x in files]\n",
        "        self.trains, self.vals = train_test_split(files, test_size=0.1, random_state=42)\n",
        "    \n",
        "    def generate(self,files): \n",
        "        random.shuffle(files)\n",
        "        while True:\n",
        "            image_batch = np.zeros([self.batch_size,self.image_size,self.image_size,3])\n",
        "            label_batch = np.zeros([self.batch_size,self.image_size,self.image_size])\n",
        "            index = random.randint(0,len(files)-self.batch_size)\n",
        "            for i,img in enumerate(files[index:index+self.batch_size]):\n",
        "        \n",
        "                ## Reading Image\n",
        "                image = cv2.imread(img)\n",
        "                image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "        \n",
        "        \n",
        "                _mask_image = cv2.imread(img.replace('raw','label'))\n",
        "                _mask_image = cv2.cvtColor(_mask_image,cv2.COLOR_BGR2GRAY)\n",
        "                _mask_image = cv2.resize(_mask_image, (self.image_size, self.image_size)) #128x128\n",
        "                mask = np.expand_dims(_mask_image, axis=0)\n",
        "            \n",
        "                ## Normalizaing \n",
        "                image = image/255.0\n",
        "                mask = mask/255.0\n",
        "            image_batch[i]=image\n",
        "            label_batch[i]=mask\n",
        "        \n",
        "            yield image_batch, label_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydtte7OEYwKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = '/content/raw'\n",
        "batch_size= 1\n",
        "gen = DataGen( train_path, image_size=512, batch_size=batch_size)\n",
        "train_gen = gen.generate(gen.trains)\n",
        "val_gen = gen.generate(gen.vals)\n",
        "\n",
        "\n",
        "train_steps = len(gen.trains)//batch_size\n",
        "valid_steps = len(gen.vals)//batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pbR9ggDpkr3",
        "colab_type": "code",
        "outputId": "90d4e8dd-0b18-4290-e891-d8ca391b489d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='val_mean_absolute_error',mode='min',verbose=1, save_best_only=True)\n",
        "model.fit_generator(train_gen,steps_per_epoch=train_steps,epochs=60,\n",
        "                    callbacks=[model_checkpoint],\n",
        "                    validation_data = val_gen,validation_steps = valid_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1546 - mean_absolute_error: 0.1552Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.0385 - mean_absolute_error: 0.0387\n",
            "Epoch 00001: val_mean_absolute_error improved from inf to 0.03874, saving model to unet_membrane.hdf5\n",
            "90/90 [==============================] - 21s 236ms/step - loss: 0.1539 - mean_absolute_error: 0.1545 - val_loss: 0.0385 - val_mean_absolute_error: 0.0387\n",
            "Epoch 2/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1572 - mean_absolute_error: 0.1578Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 19s - loss: 0.0980 - mean_absolute_error: 0.0984\n",
            "Epoch 00002: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 18s 205ms/step - loss: 0.1565 - mean_absolute_error: 0.1571 - val_loss: 0.0980 - val_mean_absolute_error: 0.0984\n",
            "Epoch 3/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1256 - mean_absolute_error: 0.1261Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 17s - loss: 0.0792 - mean_absolute_error: 0.0796\n",
            "Epoch 00003: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 18s 204ms/step - loss: 0.1252 - mean_absolute_error: 0.1257 - val_loss: 0.0792 - val_mean_absolute_error: 0.0796\n",
            "Epoch 4/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1480 - mean_absolute_error: 0.1485Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 17s - loss: 0.0442 - mean_absolute_error: 0.0444\n",
            "Epoch 00004: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 18s 203ms/step - loss: 0.1500 - mean_absolute_error: 0.1506 - val_loss: 0.0442 - val_mean_absolute_error: 0.0444\n",
            "Epoch 5/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1545 - mean_absolute_error: 0.1552Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 17s - loss: 0.0387 - mean_absolute_error: 0.0388\n",
            "Epoch 00005: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 18s 201ms/step - loss: 0.1537 - mean_absolute_error: 0.1543 - val_loss: 0.0387 - val_mean_absolute_error: 0.0388\n",
            "Epoch 6/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1318 - mean_absolute_error: 0.1323Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 19s - loss: 0.1471 - mean_absolute_error: 0.1476\n",
            "Epoch 00006: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 18s 199ms/step - loss: 0.1322 - mean_absolute_error: 0.1327 - val_loss: 0.1471 - val_mean_absolute_error: 0.1476\n",
            "Epoch 7/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1399 - mean_absolute_error: 0.1404Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.0668 - mean_absolute_error: 0.0671\n",
            "Epoch 00007: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 18s 204ms/step - loss: 0.1397 - mean_absolute_error: 0.1403 - val_loss: 0.0668 - val_mean_absolute_error: 0.0671\n",
            "Epoch 8/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1511 - mean_absolute_error: 0.1517Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.0529 - mean_absolute_error: 0.0531\n",
            "Epoch 00008: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 19s 207ms/step - loss: 0.1505 - mean_absolute_error: 0.1511 - val_loss: 0.0529 - val_mean_absolute_error: 0.0531\n",
            "Epoch 9/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1384 - mean_absolute_error: 0.1390Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 19s - loss: 0.0517 - mean_absolute_error: 0.0519\n",
            "Epoch 00009: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 19s 208ms/step - loss: 0.1395 - mean_absolute_error: 0.1400 - val_loss: 0.0517 - val_mean_absolute_error: 0.0519\n",
            "Epoch 10/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1354 - mean_absolute_error: 0.1359Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.0854 - mean_absolute_error: 0.0857\n",
            "Epoch 00010: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 19s 209ms/step - loss: 0.1357 - mean_absolute_error: 0.1362 - val_loss: 0.0854 - val_mean_absolute_error: 0.0857\n",
            "Epoch 11/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1408 - mean_absolute_error: 0.1414Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.0789 - mean_absolute_error: 0.0792\n",
            "Epoch 00011: val_mean_absolute_error did not improve from 0.03874\n",
            "90/90 [==============================] - 19s 208ms/step - loss: 0.1431 - mean_absolute_error: 0.1436 - val_loss: 0.0789 - val_mean_absolute_error: 0.0792\n",
            "Epoch 12/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1271 - mean_absolute_error: 0.1276Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 17s - loss: 0.0289 - mean_absolute_error: 0.0290\n",
            "Epoch 00012: val_mean_absolute_error improved from 0.03874 to 0.02903, saving model to unet_membrane.hdf5\n",
            "90/90 [==============================] - 19s 208ms/step - loss: 0.1257 - mean_absolute_error: 0.1262 - val_loss: 0.0289 - val_mean_absolute_error: 0.0290\n",
            "Epoch 13/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1420 - mean_absolute_error: 0.1425Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.1485 - mean_absolute_error: 0.1489\n",
            "Epoch 00013: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 19s 206ms/step - loss: 0.1410 - mean_absolute_error: 0.1415 - val_loss: 0.1485 - val_mean_absolute_error: 0.1489\n",
            "Epoch 14/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1500 - mean_absolute_error: 0.1506Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 17s - loss: 0.0796 - mean_absolute_error: 0.0799\n",
            "Epoch 00014: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 18s 205ms/step - loss: 0.1491 - mean_absolute_error: 0.1497 - val_loss: 0.0796 - val_mean_absolute_error: 0.0799\n",
            "Epoch 15/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1447 - mean_absolute_error: 0.1453Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 17s - loss: 0.0458 - mean_absolute_error: 0.0460\n",
            "Epoch 00015: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 19s 206ms/step - loss: 0.1439 - mean_absolute_error: 0.1445 - val_loss: 0.0458 - val_mean_absolute_error: 0.0460\n",
            "Epoch 16/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1565 - mean_absolute_error: 0.1571Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 17s - loss: 0.0459 - mean_absolute_error: 0.0461\n",
            "Epoch 00016: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 18s 205ms/step - loss: 0.1548 - mean_absolute_error: 0.1554 - val_loss: 0.0459 - val_mean_absolute_error: 0.0461\n",
            "Epoch 17/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1503 - mean_absolute_error: 0.1509Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.0510 - mean_absolute_error: 0.0513\n",
            "Epoch 00017: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 18s 203ms/step - loss: 0.1498 - mean_absolute_error: 0.1504 - val_loss: 0.0510 - val_mean_absolute_error: 0.0513\n",
            "Epoch 18/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1599 - mean_absolute_error: 0.1606Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.1206 - mean_absolute_error: 0.1209\n",
            "Epoch 00018: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 19s 207ms/step - loss: 0.1608 - mean_absolute_error: 0.1614 - val_loss: 0.1206 - val_mean_absolute_error: 0.1209\n",
            "Epoch 19/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1309 - mean_absolute_error: 0.1314Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.1200 - mean_absolute_error: 0.1204\n",
            "Epoch 00019: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 18s 201ms/step - loss: 0.1302 - mean_absolute_error: 0.1307 - val_loss: 0.1200 - val_mean_absolute_error: 0.1204\n",
            "Epoch 20/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1482 - mean_absolute_error: 0.1488Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.0853 - mean_absolute_error: 0.0857\n",
            "Epoch 00020: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 18s 203ms/step - loss: 0.1471 - mean_absolute_error: 0.1477 - val_loss: 0.0853 - val_mean_absolute_error: 0.0857\n",
            "Epoch 21/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1510 - mean_absolute_error: 0.1516Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 18s - loss: 0.1515 - mean_absolute_error: 0.1519\n",
            "Epoch 00021: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 18s 204ms/step - loss: 0.1503 - mean_absolute_error: 0.1509 - val_loss: 0.1515 - val_mean_absolute_error: 0.1519\n",
            "Epoch 22/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1347 - mean_absolute_error: 0.1352Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 17s - loss: 0.1210 - mean_absolute_error: 0.1213\n",
            "Epoch 00022: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 18s 201ms/step - loss: 0.1347 - mean_absolute_error: 0.1352 - val_loss: 0.1210 - val_mean_absolute_error: 0.1213\n",
            "Epoch 23/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1358 - mean_absolute_error: 0.1363Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 16s - loss: 0.1161 - mean_absolute_error: 0.1164\n",
            "Epoch 00023: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 18s 203ms/step - loss: 0.1354 - mean_absolute_error: 0.1359 - val_loss: 0.1161 - val_mean_absolute_error: 0.1164\n",
            "Epoch 24/60\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1504 - mean_absolute_error: 0.1509Epoch 1/60\n",
            "10/90 [==>...........................] - ETA: 19s - loss: 0.0826 - mean_absolute_error: 0.0829\n",
            "Epoch 00024: val_mean_absolute_error did not improve from 0.02903\n",
            "90/90 [==============================] - 18s 202ms/step - loss: 0.1487 - mean_absolute_error: 0.1492 - val_loss: 0.0826 - val_mean_absolute_error: 0.0829\n",
            "Epoch 25/60\n",
            "21/90 [======>.......................] - ETA: 11s - loss: 0.1624 - mean_absolute_error: 0.1630"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcxesAStv1yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import glob, cv2\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "model.load_weights('/content/unet_membrane.hdf5')\n",
        "\n",
        "def predict(image):\n",
        "    image = np.array(image,np.float)/255.0\n",
        "    image = np.expand_dims(image,axis=0)\n",
        "    pred = model.predict(image)[0]\n",
        "    pred = cv2.merge([pred,pred,pred])\n",
        "    return pred\n",
        "\n",
        "def plot_result(img):\n",
        "    imgname = os.path.basename(img)\n",
        "    print(imgname)\n",
        "    image = Image.open(img)\n",
        "    h,w = image.size\n",
        "    copy = image.resize((1024,1024))\n",
        "    copy = np.array(copy,np.float)\n",
        "    pred = predict(copy)\n",
        "    pred = cv2.resize(pred,(h,w))\n",
        "    blend = np.array(image)*pred\n",
        "    blend = np.asarray(blend,np.uint8)\n",
        "    savedir = 'unet-result'\n",
        "    if not os.path.isdir(savedir):\n",
        "        os.makedirs(savedir)\n",
        "    blend = Image.fromarray(blend)\n",
        "    blend.save(os.path.join(savedir,imgname))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    images = glob.glob('/content/test/*.png')\n",
        "    for image in images:\n",
        "        plot_result(image)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}