{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasohasakii/unet-segmentation/blob/master/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXF0mNZVGrRc",
        "colab_type": "code",
        "outputId": "ce3ab9a1-6d0c-453d-896d-147c0d656d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!rm -rf *\n",
        "!git clone https://github.com/yasohasakii/unet-segmentation.git\n",
        "!cp -r unet-segmentation/* ./\n",
        "!rm -rf unet-segmentation/"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unet-segmentation'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 233 (delta 8), reused 0 (delta 0), pack-reused 200\n",
            "Receiving objects: 100% (233/233), 513.91 MiB | 32.54 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Checking out files: 100% (220/220), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns9YXewiU0H8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras import backend as K\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcav7XpTWFKJ",
        "colab_type": "code",
        "outputId": "960cfd28-fe7c-4a50-bedc-df2df04a6e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    b = keras.layers.BatchNormalization()(c)\n",
        "    d = keras.layers.Dropout(0.25)(b)\n",
        "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(d)\n",
        "    return c, p\n",
        "\n",
        "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
        "    concat = keras.layers.Concatenate()([us, skip])\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    c = keras.layers.BatchNormalization()(c)\n",
        "    return c\n",
        "\n",
        "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c\n",
        "def UNet():\n",
        "    f = [64, 128, 256, 512, 1024]\n",
        "    inputs = keras.layers.Input((512, 512, 3))\n",
        "    \n",
        "    p0 = inputs\n",
        "    c1, p1 = down_block(p0, f[0]) #128 -> 64\n",
        "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
        "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
        "    c4, p4 = down_block(p3, f[3]) #16->8\n",
        "    \n",
        "    bn = bottleneck(p4, f[4])\n",
        "    \n",
        "    u1 = up_block(bn, c4, f[3]) #8 -> 16\n",
        "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
        "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
        "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
        "    \n",
        "    out = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
        "    outputs = keras.layers.Reshape((512,512))(out)\n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    return model\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "model = UNet()\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=\"mse\", metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 512, 512, 64) 1792        input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 512, 512, 64) 36928       conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 512, 512, 64) 256         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 512, 512, 64) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling2D) (None, 256, 256, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 256, 256, 128 73856       max_pooling2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 256, 256, 128 147584      conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 256, 256, 128 512         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 256, 256, 128 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling2D) (None, 128, 128, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 128, 128, 256 295168      max_pooling2d_33[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 128, 128, 256 590080      conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 128, 128, 256 1024        conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 128, 128, 256 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling2D) (None, 64, 64, 256)  0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 64, 64, 512)  1180160     max_pooling2d_34[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 64, 64, 512)  2359808     conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 64, 64, 512)  2048        conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 64, 64, 512)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling2D) (None, 32, 32, 512)  0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 32, 32, 1024) 4719616     max_pooling2d_35[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 32, 32, 1024) 9438208     conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_32 (UpSampling2D) (None, 64, 64, 1024) 0           conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 64, 64, 1536) 0           up_sampling2d_32[0][0]           \n",
            "                                                                 conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 64, 64, 512)  7078400     concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 64, 64, 512)  2359808     conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 64, 64, 512)  2048        conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_33 (UpSampling2D) (None, 128, 128, 512 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 128, 128, 768 0           up_sampling2d_33[0][0]           \n",
            "                                                                 conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 128, 128, 256 1769728     concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 128, 128, 256 590080      conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 128, 128, 256 1024        conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_34 (UpSampling2D) (None, 256, 256, 256 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 256, 256, 384 0           up_sampling2d_34[0][0]           \n",
            "                                                                 conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 256, 256, 128 442496      concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 256, 256, 128 147584      conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 256, 256, 128 512         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_35 (UpSampling2D) (None, 512, 512, 128 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 512, 512, 192 0           up_sampling2d_35[0][0]           \n",
            "                                                                 conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 512, 512, 64) 110656      concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 512, 512, 64) 36928       conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 512, 512, 64) 256         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 512, 512, 1)  65          batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 512, 512)     0           conv2d_170[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 31,386,625\n",
            "Trainable params: 31,382,785\n",
            "Non-trainable params: 3,840\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N74gPOQWabV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGen(keras.utils.Sequence):\n",
        "    def __init__(self, path, batch_size=1, image_size=512):\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        files = os.listdir(self.path)\n",
        "        files = [os.path.join(self.path,x) for x in files]\n",
        "        self.trains, self.vals = train_test_split(files, test_size=0.1, random_state=42)\n",
        "    \n",
        "    def generate(self,files): \n",
        "        random.shuffle(files)\n",
        "        while True:\n",
        "            image_batch = np.zeros([self.batch_size,self.image_size,self.image_size,3])\n",
        "            label_batch = np.zeros([self.batch_size,self.image_size,self.image_size])\n",
        "            index = random.randint(0,len(files)-self.batch_size)\n",
        "            for i,img in enumerate(files[index:index+self.batch_size]):\n",
        "        \n",
        "                ## Reading Image\n",
        "                image = Image.open(img)\n",
        "                image = image.resize((self.image_size, self.image_size))\n",
        "                image = np.array(image)\n",
        "        \n",
        "                _mask_image = Image.open(img.replace('raw','label'))\n",
        "                _mask_image = _mask_image.convert('L')\n",
        "                _mask_image = _mask_image.resize((self.image_size, self.image_size)) #128x128\n",
        "                mask = np.array(_mask_image)\n",
        "            \n",
        "                ## Normalizaing \n",
        "                image = image/255.0\n",
        "                mask = mask/255.0\n",
        "                # print(np.max(mask))\n",
        "            image_batch[i]=image\n",
        "            label_batch[i]=mask\n",
        "        \n",
        "            yield image_batch, label_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydtte7OEYwKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = '/content/raw'\n",
        "batch_size= 1\n",
        "gen = DataGen( train_path, image_size=512, batch_size=batch_size)\n",
        "train_gen = gen.generate(gen.trains)\n",
        "val_gen = gen.generate(gen.vals)\n",
        "\n",
        "\n",
        "train_steps = len(gen.trains)//batch_size\n",
        "valid_steps = len(gen.vals)//batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pbR9ggDpkr3",
        "colab_type": "code",
        "outputId": "69acd9ee-f900-4372-f17b-4f9b49305622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_checkpoint = ModelCheckpoint('unet_membrane.h5', monitor='val_mean_absolute_error',mode='min',verbose=1, save_best_only=True)\n",
        "earlystop = EarlyStopping(monitor = 'val_mean_absolute_error',patience=5,mode = 'min')\n",
        "h = model.fit_generator(train_gen,steps_per_epoch=train_steps,epochs=100,\n",
        "                    callbacks=[model_checkpoint,earlystop],\n",
        "                    validation_data = val_gen,validation_steps = valid_steps)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2542Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 35s - loss: 0.0726 - mean_absolute_error: 0.2144\n",
            "Epoch 00001: val_mean_absolute_error improved from inf to 0.21441, saving model to unet_membrane.h5\n",
            "90/90 [==============================] - 87s 968ms/step - loss: 0.1193 - mean_absolute_error: 0.2535 - val_loss: 0.0726 - val_mean_absolute_error: 0.2144\n",
            "Epoch 2/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0905 - mean_absolute_error: 0.2048Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.1227 - mean_absolute_error: 0.2607\n",
            "Epoch 00002: val_mean_absolute_error did not improve from 0.21441\n",
            "90/90 [==============================] - 74s 822ms/step - loss: 0.0904 - mean_absolute_error: 0.2048 - val_loss: 0.1227 - val_mean_absolute_error: 0.2607\n",
            "Epoch 3/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0774 - mean_absolute_error: 0.1769Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.1285 - mean_absolute_error: 0.2173\n",
            "Epoch 00003: val_mean_absolute_error did not improve from 0.21441\n",
            "90/90 [==============================] - 74s 820ms/step - loss: 0.0773 - mean_absolute_error: 0.1766 - val_loss: 0.1285 - val_mean_absolute_error: 0.2173\n",
            "Epoch 4/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0687 - mean_absolute_error: 0.1615Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.0664 - mean_absolute_error: 0.1785\n",
            "Epoch 00004: val_mean_absolute_error improved from 0.21441 to 0.17851, saving model to unet_membrane.h5\n",
            "90/90 [==============================] - 75s 835ms/step - loss: 0.0692 - mean_absolute_error: 0.1618 - val_loss: 0.0664 - val_mean_absolute_error: 0.1785\n",
            "Epoch 5/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0657 - mean_absolute_error: 0.1553Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.0518 - mean_absolute_error: 0.1267\n",
            "Epoch 00005: val_mean_absolute_error improved from 0.17851 to 0.12669, saving model to unet_membrane.h5\n",
            "90/90 [==============================] - 75s 832ms/step - loss: 0.0654 - mean_absolute_error: 0.1550 - val_loss: 0.0518 - val_mean_absolute_error: 0.1267\n",
            "Epoch 6/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0574 - mean_absolute_error: 0.1419Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.0394 - mean_absolute_error: 0.0944\n",
            "Epoch 00006: val_mean_absolute_error improved from 0.12669 to 0.09442, saving model to unet_membrane.h5\n",
            "90/90 [==============================] - 75s 835ms/step - loss: 0.0576 - mean_absolute_error: 0.1427 - val_loss: 0.0394 - val_mean_absolute_error: 0.0944\n",
            "Epoch 7/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0584 - mean_absolute_error: 0.1412Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 23s - loss: 0.2551 - mean_absolute_error: 0.4758\n",
            "Epoch 00007: val_mean_absolute_error did not improve from 0.09442\n",
            "90/90 [==============================] - 74s 819ms/step - loss: 0.0580 - mean_absolute_error: 0.1405 - val_loss: 0.2551 - val_mean_absolute_error: 0.4758\n",
            "Epoch 8/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0520 - mean_absolute_error: 0.1267Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 23s - loss: 0.0218 - mean_absolute_error: 0.0944\n",
            "Epoch 00008: val_mean_absolute_error did not improve from 0.09442\n",
            "90/90 [==============================] - 74s 817ms/step - loss: 0.0522 - mean_absolute_error: 0.1274 - val_loss: 0.0218 - val_mean_absolute_error: 0.0944\n",
            "Epoch 9/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0450 - mean_absolute_error: 0.1164Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 23s - loss: 0.0782 - mean_absolute_error: 0.1232\n",
            "Epoch 00009: val_mean_absolute_error did not improve from 0.09442\n",
            "90/90 [==============================] - 74s 817ms/step - loss: 0.0449 - mean_absolute_error: 0.1165 - val_loss: 0.0782 - val_mean_absolute_error: 0.1232\n",
            "Epoch 10/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0427 - mean_absolute_error: 0.1076Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.0511 - mean_absolute_error: 0.1016\n",
            "Epoch 00010: val_mean_absolute_error did not improve from 0.09442\n",
            "90/90 [==============================] - 74s 819ms/step - loss: 0.0425 - mean_absolute_error: 0.1071 - val_loss: 0.0511 - val_mean_absolute_error: 0.1016\n",
            "Epoch 11/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0485 - mean_absolute_error: 0.1150Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.0396 - mean_absolute_error: 0.0778\n",
            "Epoch 00011: val_mean_absolute_error improved from 0.09442 to 0.07782, saving model to unet_membrane.h5\n",
            "90/90 [==============================] - 75s 831ms/step - loss: 0.0484 - mean_absolute_error: 0.1148 - val_loss: 0.0396 - val_mean_absolute_error: 0.0778\n",
            "Epoch 12/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0422 - mean_absolute_error: 0.1125Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.0313 - mean_absolute_error: 0.1037\n",
            "Epoch 00012: val_mean_absolute_error did not improve from 0.07782\n",
            "90/90 [==============================] - 74s 819ms/step - loss: 0.0420 - mean_absolute_error: 0.1124 - val_loss: 0.0313 - val_mean_absolute_error: 0.1037\n",
            "Epoch 13/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.0898Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.0192 - mean_absolute_error: 0.0504\n",
            "Epoch 00013: val_mean_absolute_error improved from 0.07782 to 0.05040, saving model to unet_membrane.h5\n",
            "90/90 [==============================] - 75s 832ms/step - loss: 0.0316 - mean_absolute_error: 0.0899 - val_loss: 0.0192 - val_mean_absolute_error: 0.0504\n",
            "Epoch 14/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.0905Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 23s - loss: 0.0275 - mean_absolute_error: 0.0797\n",
            "Epoch 00014: val_mean_absolute_error did not improve from 0.05040\n",
            "90/90 [==============================] - 74s 817ms/step - loss: 0.0342 - mean_absolute_error: 0.0913 - val_loss: 0.0275 - val_mean_absolute_error: 0.0797\n",
            "Epoch 15/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.0897Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.0486 - mean_absolute_error: 0.0967\n",
            "Epoch 00015: val_mean_absolute_error did not improve from 0.05040\n",
            "90/90 [==============================] - 73s 816ms/step - loss: 0.0336 - mean_absolute_error: 0.0896 - val_loss: 0.0486 - val_mean_absolute_error: 0.0967\n",
            "Epoch 16/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0378 - mean_absolute_error: 0.1011Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 23s - loss: 0.0421 - mean_absolute_error: 0.0819\n",
            "Epoch 00016: val_mean_absolute_error did not improve from 0.05040\n",
            "90/90 [==============================] - 73s 814ms/step - loss: 0.0375 - mean_absolute_error: 0.1008 - val_loss: 0.0421 - val_mean_absolute_error: 0.0819\n",
            "Epoch 17/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.0933Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 23s - loss: 0.0290 - mean_absolute_error: 0.0679\n",
            "Epoch 00017: val_mean_absolute_error did not improve from 0.05040\n",
            "90/90 [==============================] - 73s 814ms/step - loss: 0.0333 - mean_absolute_error: 0.0929 - val_loss: 0.0290 - val_mean_absolute_error: 0.0679\n",
            "Epoch 18/100\n",
            "89/90 [============================>.] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.0761Epoch 1/100\n",
            "10/90 [==>...........................] - ETA: 24s - loss: 0.0257 - mean_absolute_error: 0.0747\n",
            "Epoch 00018: val_mean_absolute_error did not improve from 0.05040\n",
            "90/90 [==============================] - 73s 814ms/step - loss: 0.0278 - mean_absolute_error: 0.0759 - val_loss: 0.0257 - val_mean_absolute_error: 0.0747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcxesAStv1yG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "1faa6a01-cb3c-43e9-f013-26ba55f2b468"
      },
      "source": [
        "from PIL import Image\n",
        "import glob, cv2\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "model.load_weights('/content/unet_membrane.h5')\n",
        "\n",
        "def predict(image):\n",
        "    image = np.array(image,np.float)/255.0\n",
        "    image = np.expand_dims(image,axis=0)\n",
        "    pred = model.predict(image)[0]\n",
        "    pred = (pred-np.min(pred))/(np.max(pred)-np.min(pred))\n",
        "    pred = cv2.merge([pred,pred,pred])\n",
        "    return pred\n",
        "\n",
        "def plot_result(img):\n",
        "    imgname = os.path.basename(img)\n",
        "    print(imgname)\n",
        "    image = Image.open(img)\n",
        "    h,w = image.size\n",
        "    copy = image.resize((512,512))\n",
        "    copy = np.array(copy,np.float)\n",
        "    pred = predict(copy)\n",
        "    print(np.max(pred))\n",
        "    pred = cv2.resize(pred,(h,w))\n",
        "    blend = np.array(image)*pred\n",
        "    blend = np.asarray(blend,np.uint8)\n",
        "    savedir = 'unet-result'\n",
        "    if not os.path.isdir(savedir):\n",
        "        os.makedirs(savedir)\n",
        "    blend = Image.fromarray(blend)\n",
        "    blend.save(os.path.join(savedir,imgname))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    images = glob.glob('/content/test/*.png')\n",
        "    for image in images:\n",
        "        plot_result(image)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "671a56ce44a141acb59d6e10b28ddb3f.png\n",
            "1.0\n",
            "8396aaabe1ab42439cb2c8838cd3d783.png\n",
            "1.0\n",
            "ca967714d16b464aa8bad0bebd07687a.png\n",
            "1.0\n",
            "5221cf979fe645959c6e45e523092145.png\n",
            "1.0\n",
            "a34393704d624e0c9430e012a73b6b02.png\n",
            "1.0\n",
            "09816413ea8f42d88479f300d689fb51.png\n",
            "1.0\n",
            "566e58ce8e874cca80a2cee472361529.png\n",
            "1.0\n",
            "e5f90522a6084d3c9b9f52117e53ac4d.png\n",
            "1.0\n",
            "1135c7a4d9a84e1fbf60f60a34030267.png\n",
            "1.0\n",
            "f9a297618ecb44c0b9a74d4c863653b3.png\n",
            "1.0\n",
            "ca708ea4d3124568b9df41610be9f001.png\n",
            "1.0\n",
            "dbb4b5b5679441f4bbc643de599dc221.png\n",
            "1.0\n",
            "1fa17f9a553b4c95bf92442e6dc65340.png\n",
            "1.0\n",
            "f90f388214f24b3d944710de566c0705.png\n",
            "1.0\n",
            "bf269b76ec6c477fa30d07a6f61dce4b.png\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXdQP4d9z2Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}