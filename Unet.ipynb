{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasohasakii/unet-segmentation/blob/master/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEFXi2KYNOkE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "fb174109-4a32-4541-c799-aa705a61009e"
      },
      "source": [
        "!rm -rf *\n",
        "!git clone https://github.com/yasohasakii/unet-segmentation.git\n",
        "!cp -r unet-segmentation/* ./\n",
        "!rm -rf unet-segmentation/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unet-segmentation'...\n",
            "remote: Enumerating objects: 382, done.\u001b[K\n",
            "remote: Total 382 (delta 0), reused 0 (delta 0), pack-reused 382\n",
            "Receiving objects: 100% (382/382), 794.08 MiB | 37.07 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "Checking out files: 100% (296/296), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlYoy7ZmOMKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "44916b31-571c-40d6-81fd-292c020fadce"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "from PIL import Image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AnNP7P3OTtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#metrics were from https://www.kaggle.com/meaninglesslives/unet-plus-plus-with-efficientnet-encoder\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 0.5\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += np.sum(1-p)/np.sum(1-t)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        p = np.asarray(p,np.bool)\n",
        "        t = np.asarray(t,np.bool)\n",
        "        i = np.bitwise_and(p,t)\n",
        "        i = np.asarray(i,np.float)\n",
        "        intersection = np.sum(i)\n",
        "        u = np.bitwise_or(p,t)\n",
        "        u = np.asarray(u,np.float)\n",
        "        union = np.sum(u)\n",
        "        iou = intersection / union\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    # Tensorflow version\n",
        "    return tf.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVzXdLg2QMIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b387c9e-0e48-41c0-bd09-febf90cafa8d"
      },
      "source": [
        "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    b = keras.layers.BatchNormalization()(c)\n",
        "    d = keras.layers.Dropout(0.25)(b)\n",
        "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(d)\n",
        "    return c, p\n",
        "\n",
        "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
        "    concat = keras.layers.Concatenate()([us, skip])\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    c = keras.layers.BatchNormalization()(c)\n",
        "    return c\n",
        "\n",
        "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c\n",
        "def UNet(h=1024,w=1024):\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = keras.layers.Input((h, w, 3))\n",
        "    \n",
        "    p0 = inputs\n",
        "    c1, p1 = down_block(p0, f[0]) #1024 -> 512\n",
        "    c2, p2 = down_block(p1, f[1]) #512 -> 256\n",
        "    c3, p3 = down_block(p2, f[2]) #256 -> 128\n",
        "    c4, p4 = down_block(p3, f[3]) #128 -> 64\n",
        "    \n",
        "    bn = bottleneck(p4, f[4])\n",
        "    \n",
        "    u1 = up_block(bn, c4, f[3]) #64 -> 128\n",
        "    u2 = up_block(u1, c3, f[2]) #128 -> 256\n",
        "    u3 = up_block(u2, c2, f[1]) #256 -> 512\n",
        "    u4 = up_block(u3, c1, f[0]) #512 -> 1024\n",
        "    \n",
        "    out = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
        "    outputs = keras.layers.Reshape((h, w))(out)\n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = UNet()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 1024, 1024, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 1024, 1024, 1 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 1024, 1024, 1 2320        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 1024, 1024, 1 64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 1024, 1024, 1 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 512, 512, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 512, 512, 32) 4640        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 512, 512, 32) 9248        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 512, 512, 32) 128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 512, 512, 32) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 256, 256, 32) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 256, 256, 64) 18496       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 256, 256, 64) 256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 256, 256, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 128, 128, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 128, 128, 128 147584      conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 128)  0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 128, 128, 384 0           up_sampling2d_5[0][0]            \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 128, 128, 128 442496      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 128, 128, 128 147584      conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 128 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 256, 256, 192 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 256, 256, 64) 110656      concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 256, 256, 64) 256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 512, 512, 64) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 512, 512, 96) 0           up_sampling2d_7[0][0]            \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 512, 512, 32) 27680       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 512, 512, 32) 9248        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 512, 512, 32) 128         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2D)  (None, 1024, 1024, 3 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 1024, 1024, 4 0           up_sampling2d_8[0][0]            \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 1024, 1024, 1 6928        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 1024, 1024, 1 2320        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 1024, 1024, 1 64          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 1024, 1024, 1 17          batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 1024, 1024)   0           conv2d_38[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,964,545\n",
            "Trainable params: 1,963,585\n",
            "Non-trainable params: 960\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbXk63dtQcEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGen(keras.utils.Sequence):\n",
        "    def __init__(self, path, batch_size=1, image_size=1024):\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        files = os.listdir(self.path)\n",
        "        files = [os.path.join(self.path,x) for x in files]\n",
        "        self.trains, self.vals = train_test_split(files, test_size=0.1, random_state=42)\n",
        "    \n",
        "    def generate(self,files): \n",
        "        random.shuffle(files)\n",
        "        while True:\n",
        "            image_batch = np.zeros([self.batch_size,self.image_size,self.image_size,3])\n",
        "            label_batch = np.zeros([self.batch_size,self.image_size,self.image_size])\n",
        "            index = random.randint(0,len(files)-self.batch_size)\n",
        "            for i,img in enumerate(files[index:index+self.batch_size]):\n",
        "                rotate_angle = random.randint(0,180)\n",
        "                shift_width = random.randint(0,102)\n",
        "                shift_height = random.randint(0,102)\n",
        "        \n",
        "                ## Reading Image\n",
        "                _image = Image.open(img)\n",
        "                _image = _image.rotate(rotate_angle)\n",
        "                _image = _image.resize((self.image_size, self.image_size))\n",
        "                _image = np.array(_image)\n",
        "                image = np.zeros([self.image_size,self.image_size,3],np.uint8)\n",
        "        \n",
        "                _mask_image = Image.open(img.replace('raw','label'))\n",
        "                _mask_image = _mask_image.convert('L')\n",
        "                _mask_image = _mask_image.rotate(rotate_angle)\n",
        "                _mask_image = _mask_image.resize((self.image_size, self.image_size))\n",
        "                _mask_image = np.array(_mask_image)\n",
        "                mask = np.zeros([self.image_size,self.image_size],np.uint8)\n",
        "\n",
        "                image[shift_height:,shift_width:,:] = np.array(_image)[:self.image_size-shift_height,:self.image_size-shift_width,:]\n",
        "                mask[shift_height:,shift_width:] = np.array(_mask_image)[:self.image_size-shift_height,:self.image_size-shift_width] \n",
        "                \n",
        "                ## Normalizaing \n",
        "                image = image/255.0\n",
        "                mask = mask/255.0\n",
        "\n",
        "                image_batch[i] = image\n",
        "                label_batch[i] = mask                   \n",
        "        \n",
        "            yield image_batch, label_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOoJU3I0QjVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = '/content/raw'\n",
        "batch_size= 1\n",
        "gen = DataGen( train_path, image_size=1024, batch_size=batch_size)\n",
        "train_gen = gen.generate(gen.trains)\n",
        "val_gen = gen.generate(gen.vals)\n",
        "\n",
        "\n",
        "train_steps = len(gen.trains)//batch_size\n",
        "valid_steps = len(gen.vals)//batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNJ9_AMDRG5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32427d3a-6e08-44e6-d1b1-4030e0f79bcc"
      },
      "source": [
        "model.compile(optimizer=Adam(lr=0.0001), loss=bce_dice_loss, metrics=[my_iou_metric,'mae'])\n",
        "model_checkpoint = ModelCheckpoint('unet.h5', monitor='val_my_iou_metric',mode='max',verbose=1,save_best_only=True,save_weights_only=True)\n",
        "changelr = ReduceLROnPlateau(monitor = 'val_my_iou_metric',\n",
        "                patience=5,mode = 'max',\n",
        "                verbose = 1,\n",
        "                factor = 0.3,\n",
        "                min_lr = 0.0000001)\n",
        "h = model.fit_generator(train_gen,steps_per_epoch=train_steps,epochs=100,\n",
        "                    callbacks=[model_checkpoint,changelr],\n",
        "                    validation_data = val_gen,validation_steps = valid_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "123/123 [==============================] - 69s 563ms/step - loss: 0.8269 - my_iou_metric: 0.6754 - mean_absolute_error: 0.1992 - val_loss: 0.7922 - val_my_iou_metric: 0.5970 - val_mean_absolute_error: 0.1220\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.59701, saving model to unet.h5\n",
            "Epoch 2/100\n",
            "123/123 [==============================] - 60s 487ms/step - loss: 0.7617 - my_iou_metric: 0.7498 - mean_absolute_error: 0.1794 - val_loss: 0.8331 - val_my_iou_metric: 0.6902 - val_mean_absolute_error: 0.1409\n",
            "\n",
            "Epoch 00002: val_my_iou_metric improved from 0.59701 to 0.69021, saving model to unet.h5\n",
            "Epoch 3/100\n",
            "123/123 [==============================] - 60s 487ms/step - loss: 0.7891 - my_iou_metric: 0.7038 - mean_absolute_error: 0.1826 - val_loss: 0.8473 - val_my_iou_metric: 0.6381 - val_mean_absolute_error: 0.1457\n",
            "\n",
            "Epoch 00003: val_my_iou_metric did not improve from 0.69021\n",
            "Epoch 4/100\n",
            "123/123 [==============================] - 60s 486ms/step - loss: 0.7628 - my_iou_metric: 0.7172 - mean_absolute_error: 0.1667 - val_loss: 0.6555 - val_my_iou_metric: 0.5776 - val_mean_absolute_error: 0.1375\n",
            "\n",
            "Epoch 00004: val_my_iou_metric did not improve from 0.69021\n",
            "Epoch 5/100\n",
            "123/123 [==============================] - 60s 486ms/step - loss: 0.7372 - my_iou_metric: 0.7271 - mean_absolute_error: 0.1558 - val_loss: 0.7217 - val_my_iou_metric: 0.6101 - val_mean_absolute_error: 0.1115\n",
            "\n",
            "Epoch 00005: val_my_iou_metric did not improve from 0.69021\n",
            "Epoch 6/100\n",
            "123/123 [==============================] - 60s 485ms/step - loss: 0.6801 - my_iou_metric: 0.7057 - mean_absolute_error: 0.1429 - val_loss: 0.6468 - val_my_iou_metric: 0.5660 - val_mean_absolute_error: 0.1083\n",
            "\n",
            "Epoch 00006: val_my_iou_metric did not improve from 0.69021\n",
            "Epoch 7/100\n",
            "123/123 [==============================] - 60s 486ms/step - loss: 0.6775 - my_iou_metric: 0.7288 - mean_absolute_error: 0.1424 - val_loss: 0.7527 - val_my_iou_metric: 0.7041 - val_mean_absolute_error: 0.0899\n",
            "\n",
            "Epoch 00007: val_my_iou_metric improved from 0.69021 to 0.70407, saving model to unet.h5\n",
            "Epoch 8/100\n",
            "123/123 [==============================] - 60s 486ms/step - loss: 0.6669 - my_iou_metric: 0.7472 - mean_absolute_error: 0.1342 - val_loss: 0.7945 - val_my_iou_metric: 0.5334 - val_mean_absolute_error: 0.1170\n",
            "\n",
            "Epoch 00008: val_my_iou_metric did not improve from 0.70407\n",
            "Epoch 9/100\n",
            "123/123 [==============================] - 60s 489ms/step - loss: 0.6688 - my_iou_metric: 0.7019 - mean_absolute_error: 0.1331 - val_loss: 0.7268 - val_my_iou_metric: 0.5394 - val_mean_absolute_error: 0.1194\n",
            "\n",
            "Epoch 00009: val_my_iou_metric did not improve from 0.70407\n",
            "Epoch 10/100\n",
            "123/123 [==============================] - 60s 488ms/step - loss: 0.6867 - my_iou_metric: 0.7625 - mean_absolute_error: 0.1249 - val_loss: 0.6046 - val_my_iou_metric: 0.6556 - val_mean_absolute_error: 0.0884\n",
            "\n",
            "Epoch 00010: val_my_iou_metric did not improve from 0.70407\n",
            "Epoch 11/100\n",
            "123/123 [==============================] - 60s 487ms/step - loss: 0.6817 - my_iou_metric: 0.7370 - mean_absolute_error: 0.1181 - val_loss: 0.9841 - val_my_iou_metric: 0.5146 - val_mean_absolute_error: 0.1001\n",
            "\n",
            "Epoch 00011: val_my_iou_metric did not improve from 0.70407\n",
            "Epoch 12/100\n",
            "123/123 [==============================] - 60s 486ms/step - loss: 0.6993 - my_iou_metric: 0.7018 - mean_absolute_error: 0.1302 - val_loss: 0.5443 - val_my_iou_metric: 0.6954 - val_mean_absolute_error: 0.0900\n",
            "\n",
            "Epoch 00012: val_my_iou_metric did not improve from 0.70407\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
            "Epoch 13/100\n",
            "123/123 [==============================] - 60s 487ms/step - loss: 0.5734 - my_iou_metric: 0.7455 - mean_absolute_error: 0.1049 - val_loss: 0.7453 - val_my_iou_metric: 0.5768 - val_mean_absolute_error: 0.1019\n",
            "\n",
            "Epoch 00013: val_my_iou_metric did not improve from 0.70407\n",
            "Epoch 14/100\n",
            "123/123 [==============================] - 60s 489ms/step - loss: 0.6065 - my_iou_metric: 0.7668 - mean_absolute_error: 0.1064 - val_loss: 0.5896 - val_my_iou_metric: 0.6057 - val_mean_absolute_error: 0.0846\n",
            "\n",
            "Epoch 00014: val_my_iou_metric did not improve from 0.70407\n",
            "Epoch 15/100\n",
            "123/123 [==============================] - 60s 490ms/step - loss: 0.5820 - my_iou_metric: 0.7542 - mean_absolute_error: 0.1095 - val_loss: 0.9078 - val_my_iou_metric: 0.4846 - val_mean_absolute_error: 0.0998\n",
            "\n",
            "Epoch 00015: val_my_iou_metric did not improve from 0.70407\n",
            "Epoch 16/100\n",
            "123/123 [==============================] - 60s 489ms/step - loss: 0.6042 - my_iou_metric: 0.7723 - mean_absolute_error: 0.1115 - val_loss: 0.7140 - val_my_iou_metric: 0.6624 - val_mean_absolute_error: 0.0959\n",
            "\n",
            "Epoch 00016: val_my_iou_metric did not improve from 0.70407\n",
            "Epoch 17/100\n",
            "123/123 [==============================] - 60s 488ms/step - loss: 0.5117 - my_iou_metric: 0.7623 - mean_absolute_error: 0.0903 - val_loss: 0.6907 - val_my_iou_metric: 0.5460 - val_mean_absolute_error: 0.0966\n",
            "\n",
            "Epoch 00017: val_my_iou_metric did not improve from 0.70407\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
            "Epoch 18/100\n",
            " 13/123 [==>...........................] - ETA: 51s - loss: 0.6770 - my_iou_metric: 0.7924 - mean_absolute_error: 0.1070"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs9jcYU7RsH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import glob, cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "model.load_weights('/content/unet.h5')\n",
        "\n",
        "def predict(model,image):\n",
        "    image = np.array(image,np.float)/255.0\n",
        "    image = np.expand_dims(image,axis=0)\n",
        "    pred = model.predict(image)[0]\n",
        "    # pred = (pred-np.min(pred))/(np.max(pred)-np.min(pred))\n",
        "    pred = cv2.merge([pred,pred,pred])\n",
        "    return pred\n",
        "\n",
        "def plot_result(model,img):\n",
        "    image = Image.open(img)\n",
        "    h,w = image.size\n",
        "    copy = image.resize((1024,1024))\n",
        "    copy = np.array(copy,np.float)\n",
        "    pred = predict(model,copy)\n",
        "    pred = cv2.resize(pred,(h,w))\n",
        "    blend = np.array(image)*pred\n",
        "    blend = np.asarray(blend,np.uint8)\n",
        "    return blend\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    images = glob.glob('/content/test/*.png')\n",
        "    print(len(images))\n",
        "    for image in images:\n",
        "        print(image)\n",
        "        result = plot_result(model,image)\n",
        "        _image = np.array(Image.open(image))\n",
        "    \n",
        "        plt.figure(figsize=(16,8))\n",
        "        plt.subplot(121)\n",
        "        plt.title('raw_image')\n",
        "        plt.axis('off') \n",
        "        plt.imshow(_image)\n",
        "\n",
        "        plt.subplot(122)\n",
        "        plt.title('model_result')\n",
        "        plt.axis('off') \n",
        "        plt.imshow(result)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}